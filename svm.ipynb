{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine\n",
    "##### By MMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A) Form primal SVM as a QP problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"equ/Capture11.PNG\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"equ/Capture12.PNG\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ** $y^{(i)}$ must be multiplied to $<x^{(i)},1>$. A and b are zero!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B) Solve SVM primal form using cvxopt.solvers.qp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We concatenate w , b and $\\xi$ to a vector named Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cvxopt import matrix, solvers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_linear_separable_data():\n",
    "    # generate training data in the 2-d case\n",
    "    mean1 = np.array([0, 2])\n",
    "    mean2 = np.array([2, 0])\n",
    "    cov = np.array([[0.8, 0.6], [0.6, 0.8]])\n",
    "    X1 = np.random.multivariate_normal(mean1, cov, 100)\n",
    "    y1 = np.ones(len(X1))\n",
    "    X2 = np.random.multivariate_normal(mean2, cov, 100)\n",
    "    y2 = np.ones(len(X2)) * -1\n",
    "    return X1, y1, X2, y2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1, y1, X2, y2 = generate_linear_separable_data()\n",
    "X_train = np.concatenate((X1[:80], X2[:80]))\n",
    "y_train = np.concatenate((y1[:80], y2[:80]))\n",
    "X_test = np.concatenate((X1[80:], X2[80:]))\n",
    "y_test = np.concatenate((y1[80:], y2[80:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = 0.5\n",
    "N = 160\n",
    "d = 2\n",
    "z_dim = N + d + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "P = matrix(0, (z_dim, z_dim), 'd')\n",
    "P[0, 0] = P[1, 1] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = matrix(0, (z_dim, 1), 'd')\n",
    "for i in range(3, z_dim):\n",
    "    q[i] = C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = matrix(0, (2 * N, N + 2 + 1), 'd')\n",
    "for i in range(N):\n",
    "    G[i, 2 + 1 + i] = -1\n",
    "    G[N + i, 2 + 1 + i] = -1\n",
    "    G[i, 2] = -1 * y_train[i]\n",
    "for i in range(N):\n",
    "    for j in range(2):\n",
    "        G[i, j] = X_train[i, j] * -1 * y_train[i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = matrix(0, (2 * N, 1), 'd')\n",
    "for i in range(N):\n",
    "    h[i] = -1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     pcost       dcost       gap    pres   dres\n 0: -3.2826e+01  1.4089e+02  1e+03  3e+00  6e+01\n 1:  7.1597e+01 -6.7082e+01  2e+02  3e-01  6e+00\n 2:  1.6071e+01 -2.9535e+00  2e+01  3e-02  6e-01\n 3:  5.5875e+00  2.0044e+00  4e+00  5e-03  9e-02\n 4:  4.1853e+00  2.9092e+00  1e+00  1e-03  2e-02\n 5:  3.7840e+00  3.0974e+00  7e-01  4e-04  8e-03\n 6:  3.5697e+00  3.2663e+00  3e-01  5e-16  6e-15\n 7:  3.4093e+00  3.3956e+00  1e-02  4e-16  2e-14\n 8:  3.4018e+00  3.4016e+00  1e-04  4e-16  5e-15\n 9:  3.4017e+00  3.4017e+00  1e-06  5e-16  9e-15\nOptimal solution found.\n"
     ]
    }
   ],
   "source": [
    "sol = solvers.qp(P, q, G, h)\n",
    "Z_opt = sol['x']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = Z_opt[:d]\n",
    "b = Z_opt[d]\n",
    "y_predict = []\n",
    "for i in range(40):\n",
    "    y_predict.append(np.sign(np.matmul(np.transpose(w), X_test[i]) + b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, y_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C ) Why strong duality is satisfied?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem is a QP form thus is a convex problem. On the other hand Slatter's conditions is satisfed because for a data classified correctly but is inside margin, inequality constraint is inactive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D) Obtain KKT conditions for this problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"equ/Capture.PNG\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E) Derive dual form of SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get derivative from Lagrangian obtained above :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"equ/Capture5.PNG\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By substituting w and C to Lagrangian we obtain dual function g hence dual problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F) Obtain optimal w,b based on $\\alpha$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"equ/Capture3.PNG\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each of the samples that has $\\alpha$ > 0 is on the margin , thus we solve for b using any of support vectors :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"equ/Capture4.PNG\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### G) Prove that gram matrice for RBF kernel is P.S.D."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gram matrice is symmetric thus we could prove that all of eigenvalues is non-negative. It is sufficient to investigate 2*2 matrices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"equ/Capture7.PNG\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### H ) Form dual SVM problem as a QP problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"equ/Capture10.PNG\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I ) Implement dual form of SVM using gaussian kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_non_linear_separable_data():\n",
    "    mean1 = [-1, 2]\n",
    "    mean2 = [1, -1]\n",
    "    mean3 = [4, -4]\n",
    "    mean4 = [-4, 4]\n",
    "    cov = [[1.0,0.8], [0.8, 1.0]]\n",
    "    X1 = np.random.multivariate_normal(mean1, cov, 50)\n",
    "    X1 = np.vstack((X1, np.random.multivariate_normal(mean3, cov, 50)))\n",
    "    y1 = np.ones(len(X1))\n",
    "    X2 = np.random.multivariate_normal(mean2, cov, 50)\n",
    "    X2 = np.vstack((X2, np.random.multivariate_normal(mean4, cov, 50)))\n",
    "    y2 = np.ones(len(X2)) * -1\n",
    "    return X1, y1, X2, y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1, y1, X2, y2 = generate_non_linear_separable_data()\n",
    "X_train = np.concatenate((X1[:80], X2[:80]))\n",
    "y_train = np.concatenate((y1[:80], y2[:80]))\n",
    "X_test = np.concatenate((X1[80:], X2[80:]))\n",
    "y_test = np.concatenate((y1[80:], y2[80:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "diag_y = matrix(0, (N, N), 'd')\n",
    "for i in range(N):\n",
    "    diag_y[i, i] = y_train[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = matrix(-1, (N, 1), 'd')\n",
    "\n",
    "A = matrix(0, (1, N), 'd')\n",
    "for i in range(N):\n",
    "    A[0, i] = y_train[i]\n",
    "\n",
    "b = matrix(0, (1, 1), 'd')\n",
    "\n",
    "G = matrix(0, (2*N, N), 'd')\n",
    "for i in range(N):\n",
    "    G[i, i] = -1\n",
    "    G[i + N, i] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gamma :  10  ,C :  0.01 \tAccuracy :  0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gamma :  10  ,C :  0.1 \tAccuracy :  0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gamma :  10  ,C :  0.5 \tAccuracy :  0.725\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gamma :  10  ,C :  1 \tAccuracy :  1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gamma :  50  ,C :  0.01 \tAccuracy :  0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gamma :  50  ,C :  0.1 \tAccuracy :  0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gamma :  50  ,C :  0.5 \tAccuracy :  0.55\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gamma :  50  ,C :  1 \tAccuracy :  0.95\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gamma :  100  ,C :  0.01 \tAccuracy :  0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gamma :  100  ,C :  0.1 \tAccuracy :  0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gamma :  100  ,C :  0.5 \tAccuracy :  0.525\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gamma :  100  ,C :  1 \tAccuracy :  0.925\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gamma :  500  ,C :  0.01 \tAccuracy :  0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gamma :  500  ,C :  0.1 \tAccuracy :  0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gamma :  500  ,C :  0.5 \tAccuracy :  0.5\ngamma :  500  ,C :  1 \tAccuracy :  0.675\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "gamma_list = [10, 50, 100, 500]\n",
    "C_list = [0.01, 0.1, 0.5, 1]\n",
    "\n",
    "for gamma in gamma_list:\n",
    "    for C in C_list:\n",
    "        Gram = matrix(0, (N, N), 'd')\n",
    "        for i in range(N):\n",
    "            for j in range(N):\n",
    "                Gram[i, j] = math.exp(-gamma * (np.linalg.norm(X_train[i] - X_train[j]) ** 2))\n",
    "        P = matrix(np.matmul(np.matmul(diag_y, Gram), diag_y.T))\n",
    "        \n",
    "        h = matrix(0, (2*N, 1), 'd')\n",
    "        for i in range(N, 2*N):\n",
    "            h[i, 0] = C\n",
    "            \n",
    "        solvers.options['show_progress'] = False\n",
    "        sol = solvers.qp(P, q, G, h, A, b)\n",
    "        alpha = (sol['x'])\n",
    "        for i in range(N):\n",
    "            if alpha[i] < 10**-7:\n",
    "                alpha[i] = 0\n",
    "\n",
    "        sv = X_train[np.argmax(alpha)]\n",
    "        sv_label = y_train[np.argmax(alpha)]\n",
    "        temp = 0\n",
    "        for i in range(N):\n",
    "            temp = temp + alpha[i] * y_train[i] * math.exp(-gamma * (np.linalg.norm(X_train[i] - sv) ** 2))\n",
    "        w0 = temp - sv_label\n",
    "        \n",
    "        y_predict = []\n",
    "        for i in range(40):\n",
    "            temp = 0\n",
    "            for j in range(N):\n",
    "                temp = temp + alpha[j] * y_train[j] * math.exp(-gamma * (np.linalg.norm(X_train[j] - X_test[i]) ** 2))\n",
    "            y_predict.append(np.sign(temp - w0))\n",
    "            \n",
    "        from sklearn.metrics import accuracy_score\n",
    "        print(\"gamma : \", gamma, \" ,C : \", C, \"\\tAccuracy : \", accuracy_score(y_test, y_predict))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
